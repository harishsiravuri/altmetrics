{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the JSON dump into CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_path= 'C:\\\\Users\\\\haris\\\\Documents\\\\697\\\\massive dataset\\\\data\\\\'\n",
    "dump_path= \"C:\\\\Users\\\\haris\\\\Desktop\\\\10\\\\sampled.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100001.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100015.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100016.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100028.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100029.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100030.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100036.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100059.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100063.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100068.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100069.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100080.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100087.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100088.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100109.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100123.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100124.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100126.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100142.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100146.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100185.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100188.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100189.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100210.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100211.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100232.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100234.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100255.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100263.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100276.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100278.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100285.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100292.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100295.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100304.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100336.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100339.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100343.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100347.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100364.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100389.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100425.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100488.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100492.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100496.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100503.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100509.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100523.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100558.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100579.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100604.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100607.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100619.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100623.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100628.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100630.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100631.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100633.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100637.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100638.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100666.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100668.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100674.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100678.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100680.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100699.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100708.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100728.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100735.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100739.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100760.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100761.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100792.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100809.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100810.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100850.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100864.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100871.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100907.json\n",
      "C:\\Users\\haris\\Documents\\697\\massive dataset\\data\\10\\100913.json\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-03a865bcebfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mfile_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubdir_path\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                 \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m                     \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                     \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda3\\lib\\_bootlocale.py\u001b[0m in \u001b[0;36mgetpreferredencoding\u001b[0;34m(do_setlocale)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"win\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[1;32mdef\u001b[0m \u001b[0mgetpreferredencoding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdo_setlocale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_locale\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getdefaultlocale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open(dump_path,'w') as sampledfile:\n",
    "    datawriter=csv.writer(sampledfile, delimiter=',',quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    datawriter.writerow(['altmetric_id','mendeley_readers','citeulikereaders','connoteareaders','blog_users','blogs_posts_count','news_unique_users','total_posts_count','wiki_posts_count','facebook_users','facebook_posts','twitter_users','twitter_posts','citation_page','other_articles','mean','rank','perc','scored_higher_than','sample_size','users_lecturer','users_librarian','users_student_bachelor','users_student_master','users_student_pg','users_student_phd','users_student_doct','users_researcher','users_other','users_prof_assoc','users_prof','users_medi','users_ss','users_psych','users_earth','users_agri','users_arts','users_us','users_th','users_ie','users_id','users_au','users_gb','altmetric_score','altmetric_score_1y','altmetric_score_6m','altmetric_score_3m','altmetric_score_1m','altmetric_score_1w','altmetric_score_6d','altmetric_score_5d','altmetric_score_4d','altmetric_score_3d','altmetric_score_3d','altmetric_score_1d'])    \n",
    "    for dirname in os.listdir(root_path):\n",
    "        subdir_path=root_path+dirname+'\\\\'\n",
    "        for filename in os.listdir(subdir_path):\n",
    "            file_path=subdir_path+filename\n",
    "            if(file_path[-4:]=='json'):\n",
    "                with open(file_path) as json_data:\n",
    "                    count=0\n",
    "                    data=json.load(json_data)\n",
    "                    if 'altmetric_id' in data:\n",
    "                        altmetric_id=data['altmetric_id']\n",
    "                        if 'readers' in data['counts'] and 'mendeley' in data['counts']['readers'] and isinstance(data['counts']['readers']['mendeley'], int):\n",
    "                            mendeley_readers=data['counts']['readers']['mendeley']\n",
    "                            count+=1\n",
    "                        else:\n",
    "                            mendeley_readers=0\n",
    "                        if 'readers' in data['counts'] and 'citeulike' in data['counts']['readers'] and isinstance(data['counts']['readers']['citeulike'], int):\n",
    "                            citeulikereaders=data['counts']['readers']['citeulike']\n",
    "                            count+=1\n",
    "                        else:\n",
    "                            citeulikereaders=0\n",
    "                        if 'readers' in data['counts'] and 'connotea' in data['counts']['readers'] and isinstance(data['counts']['readers']['connotea'], int):\n",
    "                            connoteareaders=data['counts']['readers']['connotea']\n",
    "                            count+=1\n",
    "                        else:\n",
    "                            connoteareaders=0\n",
    "                        if 'blogs' in data['counts'] and 'unique_users_count' in data['counts']['blogs'] and isinstance(data['counts']['blogs']['unique_users_count'], int):\n",
    "                            blog_users=data['counts']['blogs']['unique_users_count']\n",
    "                            count+=1\n",
    "                        else:\n",
    "                            blog_users=0\n",
    "                        if 'blogs' in data['counts'] and 'posts_count' in data['counts']['blogs'] and isinstance(data['counts']['blogs']['posts_count'], int):\n",
    "                            blogs_posts_count=data['counts']['blogs']['posts_count']\n",
    "                            count+=1\n",
    "                        else:\n",
    "                            blogs_posts_count=0\n",
    "                        if 'news' in data['counts'] and isinstance(data['counts']['news']['unique_users_count'], int):\n",
    "                            news_unique_users=data['counts']['news']['unique_users_count']\n",
    "                            count+=1\n",
    "                        else:\n",
    "                            news_unique_users=0\n",
    "                        if 'posts_count' in data['counts']['total'] and isinstance(data['counts']['total']['posts_count'], int):\n",
    "                            total_posts_count=data['counts']['total']['posts_count']\n",
    "                            count+=1\n",
    "                        else:\n",
    "                            total_posts_count=0\n",
    "                        if 'wikipedia' in data['counts'] and isinstance(data['counts']['wikipedia']['unique_users_count'], int):\n",
    "                            wiki_posts_count=data['counts']['wikipedia']['unique_users_count']\n",
    "                            count+=1\n",
    "                        else:\n",
    "                            wiki_posts_count=0\n",
    "                        if 'startpage' in data['citation'] and isinstance(data['citation']['startpage'], int):\n",
    "                            citation_page=data['citation']['startpage']\n",
    "                            count+=1\n",
    "                        else:\n",
    "                            citation_page=0\n",
    "                        if 'facebook' in data['counts'] and 'unique_users_count' in data['counts']['facebook']:\n",
    "                            facebook_users=data['counts']['facebook']['unique_users_count']\n",
    "                            count+=1\n",
    "                        else:\n",
    "                            facebook_users=0\n",
    "                        if 'facebook' in data['counts'] and 'posts_count' in data['counts']['facebook']:\n",
    "                            facebook_posts=data['counts']['facebook']['posts_count']\n",
    "                            count+=1\n",
    "                        else:\n",
    "                            facebook_posts=0\n",
    "                        if 'twitter' in data['counts'] and 'unique_users_count' in data['counts']['twitter']:\n",
    "                            twitter_users=data['counts']['twitter']['unique_users_count']\n",
    "                            count+=1\n",
    "                        else:\n",
    "                            twitter_users=0\n",
    "                        if 'twitter' in data['counts'] and 'posts_count' in data['counts']['twitter']:\n",
    "                            twitter_posts=data['counts']['twitter']['posts_count']\n",
    "                            count+=1\n",
    "                        else:\n",
    "                            twitter_posts=0\n",
    "                        altmetric_score=data['altmetric_score']['score']\n",
    "                        altmetric_score_1y=data['altmetric_score']['score_history']['1y']\n",
    "                        altmetric_score_6m=data['altmetric_score']['score_history']['6m']\n",
    "                        altmetric_score_3m=data['altmetric_score']['score_history']['3m']\n",
    "                        altmetric_score_1m=data['altmetric_score']['score_history']['1m']\n",
    "                        altmetric_score_1w=data['altmetric_score']['score_history']['1w']\n",
    "                        altmetric_score_6d=data['altmetric_score']['score_history']['6d']\n",
    "                        altmetric_score_5d=data['altmetric_score']['score_history']['5d']\n",
    "                        altmetric_score_4d=data['altmetric_score']['score_history']['4d']\n",
    "                        altmetric_score_3d=data['altmetric_score']['score_history']['3d']\n",
    "                        altmetric_score_1d=data['altmetric_score']['score_history']['1d']\n",
    "                        if data['altmetric_score']['context_for_score']!=None and 'total_number_of_other_articles' in data['altmetric_score']['context_for_score']['all'] and isinstance(data['altmetric_score']['context_for_score']['all']['total_number_of_other_articles'], int):\n",
    "                            other_articles=data['altmetric_score']['context_for_score']['all']['total_number_of_other_articles']\n",
    "                            count+=1\n",
    "                        else:\n",
    "                            other_articles=0\n",
    "                        if data['altmetric_score']['context_for_score']!=None and 'mean' in data['altmetric_score']['context_for_score']['all']:\n",
    "                            mean=data['altmetric_score']['context_for_score']['all']['mean']\n",
    "                            count+=1\n",
    "                        else:\n",
    "                            mean=0\n",
    "                        if data['altmetric_score']['context_for_score']!=None and 'rank' in data['altmetric_score']['context_for_score']['all']:\n",
    "                            rank=data['altmetric_score']['context_for_score']['all']['rank']\n",
    "                            count+=1\n",
    "                        else:\n",
    "                            rank=0\n",
    "                        if data['altmetric_score']['context_for_score']!=None and 'this_scored_higher_than_pct' in data['altmetric_score']['context_for_score']['all']:\n",
    "                            perc=data['altmetric_score']['context_for_score']['all']['this_scored_higher_than_pct']\n",
    "                            count+=1\n",
    "                        else:\n",
    "                            perc=0\n",
    "                        if data['altmetric_score']['context_for_score']!=None and 'this_scored_higher_than' in data['altmetric_score']['context_for_score']['all']:\n",
    "                            scored_higher_than=data['altmetric_score']['context_for_score']['all']['this_scored_higher_than']\n",
    "                            count+=1\n",
    "                        else:\n",
    "                            scored_higher_than=0\n",
    "                        if data['altmetric_score']['context_for_score']!=None and 'sample_size' in data['altmetric_score']['context_for_score']['all']:\n",
    "                            sample_size=data['altmetric_score']['context_for_score']['all']['sample_size']\n",
    "                            count+=1\n",
    "                        else:\n",
    "                            sample_size=0\n",
    "                        if 'users' in data['demographics'] and 'mendeley' in data['demographics']['users'] and 'Librarian' in data['demographics']['users']['mendeley']['by_status']:\n",
    "                            users_librarian=data['demographics']['users']['mendeley']['by_status']['Librarian']\n",
    "                            count+=1\n",
    "                        else:\n",
    "                            users_librarian=0\n",
    "                        if 'users' in data['demographics'] and 'mendeley' in data['demographics']['users'] and 'Lecturer' in data['demographics']['users']['mendeley']['by_status']:\n",
    "                            users_lecturer=data['demographics']['users']['mendeley']['by_status']['Lecturer']\n",
    "                            count+=1\n",
    "                        else:\n",
    "                            users_lecturer=0\n",
    "                        if 'users' in data['demographics'] and 'mendeley' in data['demographics']['users'] and 'Student > Bachelor' in data['demographics']['users']['mendeley']['by_status']:\n",
    "                            users_student_bachelor=data['demographics']['users']['mendeley']['by_status']['Student  > Bachelor']\n",
    "                            count+=1\n",
    "                        else:\n",
    "                            users_student_bachelor=0\n",
    "                        if 'users' in data['demographics'] and 'mendeley' in data['demographics']['users'] and 'Student > Master' in data['demographics']['users']['mendeley']['by_status']:\n",
    "                            users_student_master=data['demographics']['users']['mendeley']['by_status']['Student  > Master']\n",
    "                            count+=1\n",
    "                        else:\n",
    "                            users_student_master=0\n",
    "                        if 'users' in data['demographics'] and 'mendeley' in data['demographics']['users'] and 'Student > Postgraduate' in data['demographics']['users']['mendeley']['by_status']:\n",
    "                            users_student_pg=data['demographics']['users']['mendeley']['by_status']['Student  > Postgraduate']\n",
    "                            count+=1\n",
    "                        else:\n",
    "                            users_student_pg=0\n",
    "                        if 'users' in data['demographics'] and 'mendeley' in data['demographics']['users'] and 'Student  > Ph. D. Student' in data['demographics']['users']['mendeley']['by_status']:\n",
    "                            users_student_phd=data['demographics']['users']['mendeley']['by_status']['Student  > Ph. D. Student']\n",
    "                            count+=1\n",
    "                        else:\n",
    "                            users_student_phd=0\n",
    "                        if 'users' in data['demographics'] and 'mendeley' in data['demographics']['users'] and 'Student  > Doctoral Student' in data['demographics']['users']['mendeley']['by_status']:\n",
    "                            users_student_doct=data['demographics']['users']['mendeley']['by_status']['Student  > Doctoral Student']\n",
    "                            count+=1\n",
    "                        else:\n",
    "                            users_student_doct=0\n",
    "                        if 'users' in data['demographics'] and 'mendeley' in data['demographics']['users'] and 'Researcher' in data['demographics']['users']['mendeley']['by_status']:\n",
    "                            users_researcher=data['demographics']['users']['mendeley']['by_status']['Researcher']\n",
    "                            count+=1\n",
    "                        else:\n",
    "                            users_researcher=0\n",
    "                        if 'users' in data['demographics'] and 'mendeley' in data['demographics']['users'] and 'Other' in data['demographics']['users']['mendeley']['by_status']:\n",
    "                            users_other=data['demographics']['users']['mendeley']['by_status']['Other']\n",
    "                            count+=1\n",
    "                        else:\n",
    "                            users_other=0\n",
    "                        if 'users' in data['demographics'] and 'mendeley' in data['demographics']['users'] and 'Professor > Associate Professor' in data['demographics']['users']['mendeley']['by_status']:\n",
    "                            users_prof_assoc=data['demographics']['users']['mendeley']['by_status']['Professor > Associate Professor']\n",
    "                            count+=1\n",
    "                        else:\n",
    "                            users_prof_assoc=0\n",
    "                        if 'users' in data['demographics'] and 'mendeley' in data['demographics']['users'] and 'Professor' in data['demographics']['users']['mendeley']['by_status']:\n",
    "                            users_prof=data['demographics']['users']['mendeley']['by_status']['Professor']\n",
    "                            count+=1\n",
    "                        else:\n",
    "                            users_prof=0\n",
    "                        if 'users' in data['demographics'] and 'mendeley' in data['demographics']['users'] and 'Medicine and Dentistry' in data['demographics']['users']['mendeley']['by_discipline']:\n",
    "                            users_medi=data['demographics']['users']['mendeley']['by_discipline']['Medicine and Dentistry']\n",
    "                            count+=1\n",
    "                        else:\n",
    "                            users_medi=0\n",
    "                        if 'users' in data['demographics'] and 'mendeley' in data['demographics']['users'] and 'Social Sciences' in data['demographics']['users']['mendeley']['by_discipline']:\n",
    "                            users_ss=data['demographics']['users']['mendeley']['by_discipline']['Social Sciences']\n",
    "                            count+=1\n",
    "                        else:\n",
    "                            users_ss=0\n",
    "                        if 'users' in data['demographics'] and 'mendeley' in data['demographics']['users'] and 'Psychology' in data['demographics']['users']['mendeley']['by_discipline']:\n",
    "                            users_psych=data['demographics']['users']['mendeley']['by_discipline']['Psychology']\n",
    "                            count+=1\n",
    "                        else:\n",
    "                            users_psych=0\n",
    "                        if 'users' in data['demographics'] and 'mendeley' in data['demographics']['users'] and 'Earth and Planetary Sciences' in data['demographics']['users']['mendeley']['by_discipline']:\n",
    "                            users_earth=data['demographics']['users']['mendeley']['by_discipline']['Earth and Planetary Sciences']\n",
    "                            count+=1\n",
    "                        else:\n",
    "                            users_earth=0\n",
    "                        if 'users' in data['demographics'] and 'mendeley' in data['demographics']['users'] and 'Agricultural and Biological Sciences' in data['demographics']['users']['mendeley']['by_discipline']:\n",
    "                            users_agri=data['demographics']['users']['mendeley']['by_discipline']['Agricultural and Biological Sciences']\n",
    "                            count+=1\n",
    "                        else:\n",
    "                            users_agri=0\n",
    "                        if 'users' in data['demographics'] and 'mendeley' in data['demographics']['users'] and 'Arts and Humanities' in data['demographics']['users']['mendeley']['by_discipline']:\n",
    "                            users_arts=data['demographics']['users']['mendeley']['by_discipline']['Arts and Humanities']\n",
    "                            count+=1\n",
    "                        else:\n",
    "                            users_arts=0\n",
    "                        if 'geo' in data['demographics'] and 'mendeley' in data['demographics']['geo']:\n",
    "                            if 'US' in data['demographics']['geo']['mendeley']:\n",
    "                                users_us=data['demographics']['geo']['mendeley']['US']\n",
    "                                count+=1\n",
    "                            else:\n",
    "                                users_us=0\n",
    "                            if 'TH' in data['demographics']['geo']['mendeley']:\n",
    "                                users_th=data['demographics']['geo']['mendeley']['TH']\n",
    "                                count+=1\n",
    "                            else:\n",
    "                                users_th=0\n",
    "                            if 'IE' in data['demographics']['geo']['mendeley']:\n",
    "                                users_ie=data['demographics']['geo']['mendeley']['IE']\n",
    "                                count+=1\n",
    "                            else:\n",
    "                                users_ie=0\n",
    "                            if 'ID' in data['demographics']['geo']['mendeley']:\n",
    "                                users_id=data['demographics']['geo']['mendeley']['ID']\n",
    "                                count+=1\n",
    "                            else:\n",
    "                                users_id=0\n",
    "                            if 'AU' in data['demographics']['geo']['mendeley']:\n",
    "                                users_au=data['demographics']['geo']['mendeley']['AU']\n",
    "                                count+=1\n",
    "                            else:\n",
    "                                users_au=0\n",
    "                            if 'GB' in data['demographics']['geo']['mendeley']:\n",
    "                                users_gb=data['demographics']['geo']['mendeley']['GB']\n",
    "                                count+=1\n",
    "                            else:\n",
    "                                users_gb=0\n",
    "                        else:\n",
    "                            users_us=0\n",
    "                            users_th=0\n",
    "                            users_ie=0\n",
    "                            users_id=0\n",
    "                            users_au=0\n",
    "                            users_gb=0\n",
    "                        if count>30:\n",
    "                            datawriter.writerow([altmetric_id,mendeley_readers,citeulikereaders,connoteareaders,blog_users,blogs_posts_count,news_unique_users,total_posts_count,wiki_posts_count,facebook_users,facebook_posts,twitter_users,twitter_posts,citation_page,other_articles,mean,rank,perc,scored_higher_than,sample_size,users_lecturer,users_student_bachelor,users_student_master,users_student_pg,users_student_phd,users_student_doct,users_researcher,users_other,users_prof_assoc,users_prof,users_medi,users_ss,users_psych,users_earth,users_agri,users_arts,users_us,users_th,users_ie,users_id,users_au,users_gb,altmetric_score,altmetric_score_1y,altmetric_score_6m,altmetric_score_3m,altmetric_score_1m,altmetric_score_1w,altmetric_score_6d,altmetric_score_5d,altmetric_score_4d,altmetric_score_3d,altmetric_score_3d,altmetric_score_1d])\n",
    "                            print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
